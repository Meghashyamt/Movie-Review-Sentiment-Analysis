# -*- coding: utf-8 -*-
"""Movie_Review_Sentiment_Analysis including vadar.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lQ7UfQg0oZuCuUBm6uL0U0NOIt5vdxl-

**Objective:**

Sentiment Analysis is the process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer's attitude towards a particular topic, product, etc. is positive, negative, or neutral.
In this kernel, we will be creating a model which predicts sentiment of IMDB reviews.

**Data Description:**

The core dataset contains 50,000 reviews split evenly into 25k train and 25k test sets. The overall distribution of labels is balanced (25k pos and 25k neg). In the labeled train/test sets, a negative review has a score <= 4 out of 10, and a positive review has a score >= 7 out of 10. Thus reviews with more neutral ratings are not included in the train/test sets.

# Importing Libraries
"""

import numpy as np
import pandas as pd
import os
import nltk
import re
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers

from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from IPython.display import HTML
from pathlib import Path

!unzip imdb-movie-reviews-dataset.zip

"""# Importing the Dataset"""

file_path = "aclImdb/"
pos_filenames = [file_path + "/train/pos/" + x for x in os.listdir(file_path + "train/pos/") if x.endswith(".txt")]
neg_filenames = [file_path + "/train/neg/" + x for x in os.listdir(file_path + "train/neg/") if x.endswith(".txt")]

positiveReviews, negativeReviews = [], []
for f in pos_filenames:
    positiveReviews.append(Path(f).read_text())

for f in neg_filenames:
    negativeReviews.append(Path(f).read_text())

"""## **Labelled Data with Positive as 1 and Negative as 0**"""

#Labelled data 1 'positive'  0 'negative'
dataset = pd.concat([
    pd.DataFrame({"review":positiveReviews, "label":1, "file":pos_filenames}),
    pd.DataFrame({"review":negativeReviews, "label":0, "file":neg_filenames})
], ignore_index=True).sample(frac=1, random_state=1)

dataset.head()

data=dataset.iloc[:,0:2]

"""## **Visualisation of Labelled data**"""

import seaborn as sns
sns.set(style="darkgrid")
#movie = sns.load_dataset("dataset")
ax = sns.countplot(x="label", data=dataset)

"""**Positive Review**: This was a great movie! Even though there was only about 15 people including myself there it was great! My friend and I laughed a lot. My mom even enjoyed it. There was two middle aged women there and a mid 20 year old there and they seemed to enjoy it. I love the part where Corky and Ned are like both liking Nancy and stuff its cute lol. And when she gets her roadster and Ned is there. Yeah This was a great movie even thought people underestimated it lol. Go See it i bet you'll enjoy it!! I really enjoyed it and so did my friend. 

People were so tough on this movie and they hadn't even seen it. I bet next time they will give the movie and actresses a chance. They all did a great job in my opinion. But if you have young kids its still appropriate. I will probably take my 7 year old niece to watch it too.

**Negative Review:** A bloody maniac with cannibalistic tendencies rapes a woman. He's been shot by two policemen and then he is risen from the grave because of some sort of satanic ceremonial rite preformed by an evil heresy. The hunting of women continues by this zombie-demon. The sacrificed baby returns from the grave and wants the maniac dead again, but only with the help of the police this will come true...

A bloody 65-minute mess...Horny zombies, doll-babies, S&M, corrupted and twisted policemen, repented heretics who seek refuge in front of Jesus Christ and three text-screens at the end of the film explaining us what finally happened to the policeman who survived (yes, we ought to know!)... Two decent disemboweling shots can't save the situation. I've seen worst horror-flicks, but this one was pretty bad too. Recommended only for the die-very-hard fans of the genre.
"""

from bs4 import BeautifulSoup
dataset.review = dataset.review.apply(lambda r: BeautifulSoup(r, 'html.parser').get_text())

"""## **To replace other unwanted symbols and values in the reviews**"""

dataset.review.replace(to_replace ='[^a-z A-Z]', value = '', regex = True, inplace = True)
HTML(dataset.review.get(0)[:250])

dataset.review = dataset.review.str.lower()
HTML(dataset.review.get(0)[:250])

"""## **Remove the stop-words, duplicate words and Lemmatize the words**
Stop-Word: A stop word is a commonly used word such as “the”, “a”, “an”, “in”, etc. We would not want these words to be included as feature in our dataset.

Lemmatization: Lemmatization is the process of grouping together the different inflected forms of a word so they can be analysed as a single item.
Example:

rocks : rock
corpora : corpus
better : good
learning : learn
"""

from nltk.stem import WordNetLemmatizer
import nltk
nltk.download('stopwords')
nltk.download('wordnet')

lemmatizer = WordNetLemmatizer()
english_stopwords = set(stopwords.words('english'))
dataset.review = dataset.review.apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in set(x.split()) if word not in english_stopwords]))
HTML(dataset.review.get(0)[:250])

"""## **Finding the length of the Random review taken**"""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

MAX_VOCABS = 10000

tokenizer = Tokenizer(num_words = MAX_VOCABS)
tokenizer.fit_on_texts(pd.concat([dataset.review]))
x = tokenizer.texts_to_sequences(dataset.review)

print("Length of 1st example: ", len(x[0]))
print("Length of 5th example: ",  len(x[5]))
print("Length of 16th example: ",  len(x[16]))

"""## **Maximum number of words**"""

print("Maximum number of words in the reviews: ", max([len(i) for i in x]))

from keras.preprocessing.sequence import pad_sequences
MAX_LEN = max([len(i) for i in x])
vocab_size = MAX_VOCABS + 1
x = pad_sequences(x, padding='post', maxlen=MAX_LEN, value=vocab_size)

print("Length of 1st example: ", len(x[0]))
print("Length of 5th example: ",  len(x[5]))
print("Length of 16th example: ",  len(x[16]))

"""## **Train and Testing the dataset**"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, dataset.label, test_size = 0.2, random_state = 1)

"""## **Building and Training the model**"""

#Build and Train the model
embedd_dim = 16

model = keras.Sequential([
    keras.layers.Embedding(vocab_size + 1, embedd_dim),
    keras.layers.GlobalAveragePooling1D(),
    keras.layers.Dense(212, activation='relu'),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(212, activation='relu'),
    #keras.layers.Dropout(0.1),
    keras.layers.Dense(212, activation='relu'),
    keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
history = model.fit(x_train, y_train, epochs=10,  batch_size=200, verbose = 2, validation_data = (x_test, y_test))

"""## Visualization"""

# Plot training & validation accuracy values
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

"""## **Confusion Matrix**"""

from sklearn.metrics import confusion_matrix
import seaborn as sn

y_pred = model.predict_classes(x_test)
y_true = y_test

cm = confusion_matrix(y_true, y_pred)
df_cm = pd.DataFrame(cm)
plt.figure(figsize = (5, 4))
sn.heatmap(df_cm, annot=True, fmt='g')

"""## **Classification Report**"""

from sklearn.metrics import classification_report
print(classification_report(y_true, y_pred))

"""## **Accuracy**"""

Accuracy=model.evaluate(x_test,y_test)

Accuracy

"""## To start using , what is sentiment analysis?
Sentiment analysis is simply the process of working out (statistically) whether a piece of text is positive, negative or neutral. The majority of sentiment analysis approaches take one of two forms: polarity-based, where pieces of texts are classified as either positive or negative, or valence-based, where the intensity of the sentiment is taken into account. For example, the words ‘good’ and ‘excellent’ would be treated the same in a polarity-based approach, whereas ‘excellent’ would be treated as more positive than ‘good’ in a valence-based approach.

Sentiment analysis has applications across a range of industries - it’s great for anything where you can get unstructured opinion data about a service or product. One application of sentiment analysis is for companies that have Twitter or other social media accounts to receive feedback. Obviously it’s bad business for these companies to leave negative feedback unanswered too long, and sentiment analysis can give them a quick way to find and prioritise these unhappy customers.

## How does VADER work?
VADER belongs to a type of sentiment analysis that is based on lexicons of sentiment-related words. In this approach, each of the words in the lexicon is rated as to whether it is positive or negative, and in many cases, how positive or negative. Below you can see an excerpt from VADER’s lexicon, where more positive words have higher positive ratings and more negative words have lower negative ratings.

Word Sentiment rating

tragedy -3.4

rejoiced 2.0

insane -1.7

disaster -3.1

great 3.1

To work out whether these words are positive or negative (and optionally, to what degree), the developers of these approaches need to get a bunch of people to manually rate them, which is obviously pretty expensive and time-consuming. In addition, the lexicon needs to have good coverage of the words in your text of interest, otherwise it won’t be very accurate. On the flipside, when there is a good fit between the lexicon and the text, this approach is accurate, and additionally quickly returns results even on large amounts of text. Incidentally, the developers of VADER used Amazon’s Mechanical Turk to get most of their ratings, which is a very quick and cheap way to get their ratings!

As you might have guessed, when VADER analyses a piece of text it checks to see if any of the words in the text are present in the lexicon. For example, the sentence “The food is good and the atmosphere is nice” has two words in the lexicon (good and nice) with ratings of 1.9 and 1.8 respectively.

VADER produces four sentiment metrics from these word ratings, which you can see below. The first three, positive, neutral and negative, represent the proportion of the text that falls into those categories. As you can see, our example sentence was rated as 45% positive, 55% neutral and 0% negative. The final metric, the compound score, is the sum of all of the lexicon ratings (1.9 and 1.8 in this case) which have been standardised to range between -1 and 1. In this case, our example sentence has a rating of 0.69, which is pretty strongly positive.

Sentiment metric Value
Positive 0.45

Neutral 0.55

Negative 0.00

Compound 0.69
"""

#Let’s have a look at how this works. We’ll start by installing the vaderSentiment package using pip:
  !pip install vaderSentiment

"""We need to load the SentimentIntensityAnalyser object in from the VADER package and as it’s a bit long, we’ll assign it to another name, analyser, to make it a bit easier to use."""

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

analyser = SentimentIntensityAnalyzer()

"""Finally, we’ll use the polarity_scores() method to get the sentiment metrics for a piece of text. You can see the authors have included it in a function with some print formatting to make it a bit easier to read."""

def print_sentiment_scores(sentence):
    snt = analyser.polarity_scores(sentence)
    print("{:-<40} {}".format(sentence, str(snt)))

# cleaning the  data 
def CleanData(sentence):
    processedList = ""
    
    #convert to lowercase and ignore special charcter
    sentence = re.sub(r'[^A-Za-z0-9\s.]', r'', str(sentence).lower())
    sentence = re.sub(r'\n', r' ', sentence)
    
    sentence = " ".join([word for word in sentence.split() if word not in stopWords])
    
    return sentence

# stops words for ignoring 
from nltk.corpus import stopwords
import re

stopWords = stopwords.words('english')

CleanData(dataset['review'][0])

dataset['review'] = dataset['review'].map(lambda x: CleanData(x))

dataset['review'][1]

# printing after vadar sentimental analysis done
print_sentiment_scores(dataset['review'][0])

# using while loop for printing all the statement reviews with vadar sentimental analysis
i = 1
while i < 25:
  print(print_sentiment_scores(dataset['review'][i]))
  i += 1

dataset.head()

data.head()

"""# Naive Bayes Algorithm"""

# Implementing Naive Bayes
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Performing action on the text input
from sklearn.feature_selection import SelectPercentile
from sklearn.feature_extraction.text import TfidfVectorizer

# Dividing the dataset into training and test datasets
X_train, X_test, y_train, y_test = train_test_split(data.review, data.label, test_size = 0.3, random_state = 10)

X_train.shape

y_train.head()

vectorizer = TfidfVectorizer()

X_train_transformed = vectorizer.fit_transform(X_train)
X_test_transformed = vectorizer.transform(X_test)

features_names = vectorizer.get_feature_names()

len(features_names)

X_test_transformed
#feature_names

selector = SelectPercentile(percentile = 10)
selector.fit(X_train_transformed, y_train)

X_train_transformed = selector.transform(X_train_transformed)
X_test_transformed = selector.transform(X_test_transformed)

#X_train_transformed.toarray()
X_test_transformed.toarray()

# Applying Naive Bayes theorem - multinomial NB
model_mulnb = MultinomialNB()
model_mulnb.fit(X_train_transformed, y_train)

y_predict = model_mulnb.predict(X_test_transformed)

print(confusion_matrix(y_test,y_predict))

import seaborn as sns
sns.heatmap(confusion_matrix(y_test,y_predict),annot=True)

#Accuracy
accuracy_score(y_test, y_predict)

"""# Logistic Regression"""

#importing Logistic Regression
from sklearn.linear_model import LogisticRegression

model_lg = LogisticRegression()

model_lg.fit(X_train_transformed,y_train)

predict_lg=model_lg.predict(X_test_transformed)

print(confusion_matrix(y_test,predict_lg))

import seaborn as sns
sns.heatmap(confusion_matrix(y_test,predict_lg),annot=True)

accuracy_score(y_test,predict_lg)

"""# Support Vector Classifier"""

#importing SVC
from sklearn.svm import SVC

model_svc= SVC(kernel= 'rbf', C= 1000, gamma =0.1)

model_svc.fit(X_train_transformed, y_train)

predict_svc =model_svc.predict(X_test_transformed)

print(classification_report(y_test, predict_svc))

accuracy_score(y_test, predict_svc)

from sklearn.model_selection import GridSearchCV

#Grid Search  to find the value from kernel , c , gamma
parameters=[{'kernel':['linear'], 'C':[1,10,100,1000,10000]},
           {'kernel':['rbf'],'gamma':[0.5, 0.1, 0.05,0.07,0.08], 'C':[1,10,100,1000,10000]}]

grid_model_svc= GridSearchCV(SVC(), parameters)
grid_model_svc.fit(X_train_transformed, y_train)
grid_model_svc.best_score_

grid_model_svc.best_params_

